import numpy as np

import glob, os, re

from typing import Iterator


# Models found within the GWTC datasets.
MODELS = [
    'IMRPhenomXPHM', 'SEOBNRv4PHM', 'IMRPhenomPv2', 'IMRPhenomPv3HM',
    'PrecessingSpinIMRHM', 'NRSur7dq4', 'SEOBNRv4P',
]

# The NumPy data type of the simulation models.
MODEL_DTYPE = [
    ('a_final', np.float64),
    ('mass_final[Msun]', np.float64),
    ('DL[Mpc]', np.float64),
    ('inclination[rad]', np.float64),
    ('OpeningAngleU10-40deg[rad]', np.float64),
    ('FQQ', np.float64),
    ('FNUNU', np.float64),
    ('FBZ', np.float64),
    ('FGW', np.float64),
]


class Event(np.ndarray):
    DTYPE = [
        ('inclination', np.float64),
        ('opening_angle', np.float64),
        ('flux_QQ', np.float64),
        ('flux_NU', np.float64),
        ('flux_BZ', np.float64),
        ('flux_GW', np.float64),
        ('upper_limit', np.float64),
    ]

    def __new__(cls, simulations: int):
        shape = (simulations)
        return super().__new__(cls, shape, dtype = Event.DTYPE)


def wildcard(directory: str, extension: str) -> Iterator[str]:
    '''Searches for files ending with the given `extension` within
    `directory` and yields the file path of each matching file.

    Args:
        directory (str): The directory to search within for files.
        extension (str): The file extension to limit the search to.

    Yields:
        str: The file path of each matching file.
    '''

    files = glob.glob(os.path.join(directory, f'*.{extension}'))
    for path in files:
        yield path


def extract_identifier(path: str) -> str:
    '''Extracts an identifier (name) of a gravitational wave event
    from a file path if it is present.

    Args:
        path (str): The file path to extract an identifier from.

    Returns:
        str: The identifier (name) of the gravitational wave event,
            or 'Unknown' if no identifier is present.
    '''

    pattern = re.compile(r'GW\d+_?(?=\d)\d*')
    m = pattern.search(path)
    if m:
        return m.group(0)
    return 'Unknown'


def extract_model(path: str) -> str:
    '''Extract the model used for a set of simulations from a file
    path. If the model is not found within GWTC datasets, 'Unknown'
    is returned instead.

    Args:
        path (str): The file path to extract a model from.

    Returns:
        str: The extracted model, or 'Unknown' if the model is
            not found within GWTC datasets.
    '''

    for model in MODELS:
        if model in path:
            return model
    return 'Unknown'


def find_models(directory: str) -> dict[str, str]:
    '''Searches for models within a given `directory` and returns a
    dictionary containing the identifier, model, and file path of each.

    Args:
        directory (str): The directory to search for models within.

    Returns:
        dict[str, str]: A dictionary containing the identifier and
            model of each event (as the keys) and the file path to a
            text file containing the model data (as the values).
    '''

    models = {}

    paths = sorted(wildcard(directory, 'txt'))
    for path in paths:
        identifier = extract_identifier(path)
        model = extract_model(path)
        key = f'{identifier}_{model}'
        models[key] = path

    return models


def trim_models(models: dict[str, str]) -> dict[str, str]:
    '''Trims duplicate models from the dictionary generated by
    `find_models` so that each event has a single model associated
    with it.

    Args:
        models (dict[str, str]): A dictionary containing the identifier
            and model of each event (as the keys) and the file path to
            a text file containing the model data (as the values).

    Returns:
        dict[str, str]: A dictionary containing the identifier and
            model of each event (as the keys) and the file path to a
            text file containing the model data (as the values), with
            duplicate models for each event removed.
    '''

    keeps = []

    for key in sorted(models.keys()):
        identifier = extract_identifier(key)
        model = extract_model(key)

        # If the model is not found within GWTC datasets, skip it.
        if model == 'Unknown':
            continue

        skip = False
        for keep in keeps:
            # If an event with the same identifier has already been seen,
            # skip it, as we don't want any duplicates. IMRPhenom* models
            # will be preferred because of the alphabetisation by sorting.
            if identifier == extract_identifier(keep):
                skip = True
                break
        if skip:
            continue

        keeps.append(key)

    # Return a copy of the models dictionary with only the keys in `keeps`.
    return { key: models[key] for key in keeps }


def main() -> None:
    events = {}

    # Load and trim the simulation models.
    directory = os.path.join('data', 'modelling')
    models = find_models(directory)
    models = trim_models(models)

    for key, path in models.items():
        data = np.loadtxt(path, dtype = MODEL_DTYPE)

        event = Event(data.size)
        event['inclination'] = data['inclination[rad]']
        event['opening_angle'] = data['OpeningAngleU10-40deg[rad]']
        event['flux_QQ'] = data['FQQ']
        event['flux_NU'] = data['FNUNU']
        event['flux_BZ'] = data['FBZ']
        event['flux_GW'] = data['FGW']

        events[key] = event

        identifier = extract_identifier(key)
        model = extract_model(key)
        print(f'Read {identifier} ({model}) from {os.path.basename(path)}.')

    print(f'Read {len(events)} total events.')

if __name__ == '__main__':
    main()
